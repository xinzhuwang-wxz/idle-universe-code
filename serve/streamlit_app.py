"""
(G)I-DLE Universe Streamlit çº¿ä¸Šéƒ¨ç½²æ¨¡å—
æ”¯æŒç”¨æˆ·è¾“å…¥ API keyï¼Œä¿æŠ¤éšç§
"""
import os
import sys
import streamlit as st
import logging
from typing import List, Dict, Any
import time

# è®¾ç½® FAISS å®‰å…¨ååºåˆ—åŒ–ç¯å¢ƒå˜é‡
os.environ['FAISS_ALLOW_DANGEROUS_DESERIALIZATION'] = 'True'

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
from utils.config import config
from qa_chain.lcel_chain import QaChainManager

class StreamlitApp:
    """Streamlit åº”ç”¨ç±»"""
    
    def __init__(self):
        self.config = config.deploy
        self.app_config = config.app
        self.logger = logging.getLogger(__name__)
        
        # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
        self._init_session_state()
    
    def _init_session_state(self):
        """åˆå§‹åŒ–ä¼šè¯çŠ¶æ€"""
        if "messages" not in st.session_state:
            st.session_state.messages = []
        
        if "qa_manager" not in st.session_state:
            st.session_state.qa_manager = None
        
        if "api_configured" not in st.session_state:
            st.session_state.api_configured = False
        
        if "current_model" not in st.session_state:
            st.session_state.current_model = "zhipu"
        
        if "current_embedding" not in st.session_state:
            st.session_state.current_embedding = "m3e"
    
    def create_interface(self):
        """åˆ›å»º Streamlit ç•Œé¢"""
        # é¡µé¢é…ç½®
        st.set_page_config(
            page_title=self.app_config.app_name,
            page_icon="ğŸµ",
            layout="wide",
            initial_sidebar_state="expanded"
        )
        
        # è‡ªå®šä¹‰ CSS
        st.markdown("""
        <style>
        .main-header {
            background: linear-gradient(90deg, #FF6B9D, #FF8EAB);
            padding: 1rem;
            border-radius: 10px;
            color: white;
            text-align: center;
        }
        .api-section {
            background-color: #f0f2f6;
            padding: 1rem;
            border-radius: 10px;
            margin: 1rem 0;
        }
        .chat-container {
            background-color: white;
            padding: 1rem;
            border-radius: 10px;
            box-shadow: 0 2px 4px rgba(0,0,0,0.1);
        }
        </style>
        """, unsafe_allow_html=True)
        
        # ä¸»æ ‡é¢˜
        st.markdown(f"""
        <div class="main-header">
            <h1>{self.app_config.app_name}</h1>
            <p>{self.app_config.app_description}</p>
        </div>
        """, unsafe_allow_html=True)
        
        # ä¾§è¾¹æ  - API é…ç½®
        with st.sidebar:
            st.markdown("### ğŸ”§ API é…ç½®")
            
            # é¦–å…ˆå°è¯•è‡ªåŠ¨é…ç½®
            if not st.session_state.api_configured:
                if self._auto_configure_api():
                    st.success("âœ… å·²è‡ªåŠ¨é…ç½® APIï¼ˆä½¿ç”¨å†…ç½®å¯†é’¥ï¼‰")
                else:
                    st.warning("âš ï¸ æœªæ‰¾åˆ°å†…ç½® API Keyï¼Œè¯·æ‰‹åŠ¨é…ç½®")
            
            # æ˜¾ç¤ºå½“å‰é…ç½®çŠ¶æ€
            if st.session_state.api_configured:
                st.success("âœ… API å·²é…ç½®")
                if st.session_state.current_model == "zhipu":
                    st.info("ğŸ¤– ä½¿ç”¨æ™ºè°±AI (å†…ç½®å¯†é’¥)")
                else:
                    st.info("ğŸ¤– ä½¿ç”¨ OpenAI (å†…ç½®å¯†é’¥)")
            else:
                st.warning("âš ï¸ è¯·é…ç½® API")
            
            # æ‰‹åŠ¨é…ç½®é€‰é¡¹ï¼ˆæŠ˜å ï¼‰
            with st.expander("ğŸ”§ æ‰‹åŠ¨é…ç½® APIï¼ˆå¯é€‰ï¼‰"):
                # API æä¾›å•†é€‰æ‹©
                api_provider = st.selectbox(
                    "é€‰æ‹© API æä¾›å•†",
                    ["æ™ºè°±AI (ZhipuAI)", "OpenAI"],
                    help="é€‰æ‹©ä½ è¦ä½¿ç”¨çš„ AI æœåŠ¡æä¾›å•†"
                )
                
                # API Key è¾“å…¥
                api_key = st.text_input(
                    "API Key",
                    type="password",
                    help="è¯·è¾“å…¥ä½ çš„ API Keyï¼ˆä¸ä¼šä¿å­˜åˆ°æœåŠ¡å™¨ï¼‰"
                )
                
                # æ¨¡å‹é€‰æ‹©
                if api_provider == "æ™ºè°±AI (ZhipuAI)":
                    model_name = st.selectbox(
                        "é€‰æ‹©æ¨¡å‹",
                        ["chatglm_std", "chatglm_pro", "chatglm_lite"],
                        help="é€‰æ‹©æ™ºè°±AIçš„æ¨¡å‹"
                    )
                    provider = "zhipu"
                else:
                    model_name = st.selectbox(
                        "é€‰æ‹©æ¨¡å‹",
                        ["gpt-3.5-turbo", "gpt-4"],
                        help="é€‰æ‹©OpenAIçš„æ¨¡å‹"
                    )
                    provider = "openai"
                
                # å‘é‡åŒ–æ¨¡å‹é€‰æ‹©
                embedding_type = st.selectbox(
                    "å‘é‡åŒ–æ¨¡å‹",
                    ["m3e", "openai"],
                    help="é€‰æ‹©ç”¨äºæ–‡æœ¬å‘é‡åŒ–çš„æ¨¡å‹"
                )
                
                # é…ç½®æŒ‰é’®
                if st.button("ğŸ”— æ‰‹åŠ¨é…ç½® API", type="secondary"):
                    if api_key:
                        self._configure_api(provider, model_name, api_key, embedding_type)
                    else:
                        st.error("è¯·è¾“å…¥ API Key")
            
            # å‚æ•°è®¾ç½®
            st.markdown("### âš™ï¸ å‚æ•°è®¾ç½®")
            temperature = st.slider(
                "æ¸©åº¦ (åˆ›é€ æ€§)",
                min_value=0.0,
                max_value=1.0,
                value=0.1,
                step=0.1,
                help="æ§åˆ¶å›ç­”çš„åˆ›é€ æ€§ï¼Œå€¼è¶Šé«˜è¶Šæœ‰åˆ›æ„"
            )
            
            top_k = st.slider(
                "æ£€ç´¢æ–‡æ¡£æ•°é‡",
                min_value=1,
                max_value=10,
                value=4,
                step=1,
                help="ä»çŸ¥è¯†åº“ä¸­æ£€ç´¢çš„ç›¸å…³æ–‡æ¡£æ•°é‡"
            )
            
            # æ¸…é™¤å†å²æŒ‰é’®
            if st.button("ğŸ—‘ï¸ æ¸…é™¤å¯¹è¯å†å²"):
                st.session_state.messages = []
                st.rerun()
        
        # ä¸»ç•Œé¢
        col1, col2 = st.columns([3, 1])
        
        with col1:
            st.markdown("### ğŸ’¬ å¯¹è¯ç•Œé¢")
            
            # èŠå¤©å®¹å™¨
            chat_container = st.container()
            
            with chat_container:
                # æ˜¾ç¤ºå¯¹è¯å†å²
                for message in st.session_state.messages:
                    with st.chat_message(message["role"]):
                        st.markdown(message["content"])
                
                # ç”¨æˆ·è¾“å…¥
                if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜..."):
                    # æ£€æŸ¥ API æ˜¯å¦å·²é…ç½®
                    if not st.session_state.api_configured:
                        st.error("è¯·å…ˆåœ¨ä¾§è¾¹æ é…ç½® API")
                        return
                    
                    # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
                    st.session_state.messages.append({"role": "user", "content": prompt})
                    with st.chat_message("user"):
                        st.markdown(prompt)
                    
                    # ç”Ÿæˆå›ç­”
                    with st.chat_message("assistant"):
                        message_placeholder = st.empty()
                        full_response = ""
                        
                        # æµå¼ç”Ÿæˆå›ç­”
                        try:
                            chain = st.session_state.qa_manager.get_chain(
                                model_provider=st.session_state.current_model,
                                embedding_type=st.session_state.current_embedding
                            )
                            
                            # æ›´æ–°å‚æ•°
                            chain.temperature = temperature
                            chain.top_k = top_k
                            
                            # æµå¼ç”Ÿæˆ
                            for chunk in chain.answer_stream(prompt, []):
                                full_response += chunk
                                message_placeholder.markdown(full_response + "â–Œ")
                            
                            message_placeholder.markdown(full_response)
                            
                            # æ·»åŠ åŠ©æ‰‹æ¶ˆæ¯
                            st.session_state.messages.append({"role": "assistant", "content": full_response})
                            
                        except Exception as e:
                            error_msg = f"å¤„ç†é—®é¢˜æ—¶å‡ºç°é”™è¯¯: {e}"
                            message_placeholder.error(error_msg)
                            st.session_state.messages.append({"role": "assistant", "content": error_msg})
        
        with col2:
            st.markdown("### ğŸ“Š ç³»ç»Ÿä¿¡æ¯")
            
            if st.session_state.api_configured:
                # æ˜¾ç¤ºç³»ç»Ÿä¿¡æ¯
                info_data = {
                    "API æä¾›å•†": api_provider,
                    "æ¨¡å‹": model_name,
                    "å‘é‡åŒ–": embedding_type,
                    "æ¸©åº¦": temperature,
                    "æ£€ç´¢æ•°é‡": top_k,
                    "å¯¹è¯æ•°é‡": len(st.session_state.messages)
                }
                
                for key, value in info_data.items():
                    st.metric(key, value)
                
                # ç³»ç»ŸçŠ¶æ€
                st.success("ğŸŸ¢ ç³»ç»Ÿæ­£å¸¸è¿è¡Œ")
            else:
                st.error("ğŸ”´ ç³»ç»Ÿæœªé…ç½®")
            
            # ä½¿ç”¨è¯´æ˜
            st.markdown("### ğŸ“– ä½¿ç”¨è¯´æ˜")
            st.markdown("""
            1. åœ¨ä¾§è¾¹æ é…ç½®ä½ çš„ API Key
            2. é€‰æ‹©é€‚åˆçš„æ¨¡å‹å’Œå‚æ•°
            3. åœ¨å¯¹è¯æ¡†ä¸­è¾“å…¥é—®é¢˜
            4. ç³»ç»Ÿä¼šåŸºäº (G)I-DLE çŸ¥è¯†åº“å›ç­”
            """)
    
    def _configure_api(self, provider: str, model: str, api_key: str, embedding: str):
        """é…ç½® API"""
        try:
            # è®¾ç½®ç¯å¢ƒå˜é‡ï¼ˆä»…å½“å‰ä¼šè¯ï¼‰
            if provider == "zhipu":
                os.environ["ZHIPUAI_API_KEY"] = api_key
            else:
                os.environ["OPENAI_API_KEY"] = api_key
            
            # åˆ›å»ºé—®ç­”é“¾ç®¡ç†å™¨
            qa_manager = QaChainManager()
            
            # æµ‹è¯•è¿æ¥
            test_chain = qa_manager.get_chain(
                model_provider=provider,
                model_name=model,
                embedding_type=embedding
            )
            
            # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
            st.session_state.qa_manager = qa_manager
            st.session_state.current_model = provider
            st.session_state.current_embedding = embedding
            st.session_state.api_configured = True
            
            st.success("API é…ç½®æˆåŠŸï¼")
            
        except Exception as e:
            st.error(f"API é…ç½®å¤±è´¥: {e}")
            st.session_state.api_configured = False
    
    def _auto_configure_api(self):
        """è‡ªåŠ¨é…ç½® APIï¼ˆä½¿ç”¨ç¯å¢ƒå˜é‡ï¼‰"""
        try:
            # æ£€æŸ¥ç¯å¢ƒå˜é‡
            zhipu_key = os.getenv("ZHIPUAI_API_KEY")
            openai_key = os.getenv("OPENAI_API_KEY")
            
            if zhipu_key:
                # ä½¿ç”¨æ™ºè°±AI
                provider = "zhipu"
                model = "chatglm_std"
                embedding = "m3e"
                
                # åˆ›å»ºé—®ç­”é“¾ç®¡ç†å™¨
                qa_manager = QaChainManager()
                
                # æµ‹è¯•è¿æ¥ï¼ˆæ·»åŠ æ›´è¯¦ç»†çš„é”™è¯¯å¤„ç†ï¼‰
                try:
                    test_chain = qa_manager.get_chain(
                        model_provider=provider,
                        model_name=model,
                        embedding_type=embedding
                    )
                except Exception as chain_error:
                    st.error(f"é—®ç­”é“¾åˆå§‹åŒ–å¤±è´¥: {chain_error}")
                    return False
                
                # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                st.session_state.qa_manager = qa_manager
                st.session_state.current_model = provider
                st.session_state.current_embedding = embedding
                st.session_state.api_configured = True
                
                return True
                
            elif openai_key:
                # ä½¿ç”¨ OpenAI
                provider = "openai"
                model = "gpt-3.5-turbo"
                embedding = "openai"
                
                # åˆ›å»ºé—®ç­”é“¾ç®¡ç†å™¨
                qa_manager = QaChainManager()
                
                # æµ‹è¯•è¿æ¥ï¼ˆæ·»åŠ æ›´è¯¦ç»†çš„é”™è¯¯å¤„ç†ï¼‰
                try:
                    test_chain = qa_manager.get_chain(
                        model_provider=provider,
                        model_name=model,
                        embedding_type=embedding
                    )
                except Exception as chain_error:
                    st.error(f"é—®ç­”é“¾åˆå§‹åŒ–å¤±è´¥: {chain_error}")
                    return False
                
                # ä¿å­˜åˆ°ä¼šè¯çŠ¶æ€
                st.session_state.qa_manager = qa_manager
                st.session_state.current_model = provider
                st.session_state.current_embedding = embedding
                st.session_state.api_configured = True
                
                return True
            
            return False
            
        except Exception as e:
            st.error(f"è‡ªåŠ¨é…ç½®å¤±è´¥: {e}")
            return False
    
    def run(self):
        """è¿è¡Œåº”ç”¨"""
        self.create_interface()

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='å¯åŠ¨ Streamlit åº”ç”¨')
    parser.add_argument('--port', type=int, default=8501, help='ç«¯å£å·')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    # åˆ›å»ºå¹¶è¿è¡Œåº”ç”¨
    app = StreamlitApp()
    app.run()

if __name__ == "__main__":
    main() 