"""
(G)I-DLE Universe ä¸»ç¨‹åºå…¥å£
æ•´åˆæ•°æ®é‡‡é›†ã€ç¿»è¯‘ã€å‘é‡åŒ–ã€é—®ç­”å’Œéƒ¨ç½²åŠŸèƒ½
"""
import os
import sys
import logging
import argparse
from typing import List, Dict, Any

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
sys.path.append(os.path.dirname(os.path.abspath(__file__)))
from utils.config import config

def setup_logging():
    """è®¾ç½®æ—¥å¿—"""
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
        handlers=[
            logging.FileHandler('idle_universe.log'),
            logging.StreamHandler()
        ]
    )

def check_data_exists():
    """æ£€æŸ¥æ•°æ®æ˜¯å¦å­˜åœ¨"""
    from database.create_db import DatabaseManager
    
    manager = DatabaseManager()
    info = manager.get_db_info()
    
    # æ£€æŸ¥çŸ¥è¯†åº“æ–‡ä»¶
    knowledge_files = info.get('knowledge_db_files', [])
    has_knowledge_data = len(knowledge_files) > 0
    
    # æ£€æŸ¥å‘é‡æ•°æ®åº“
    has_vector_db = info.get('vector_db_exists', False)
    
    return has_knowledge_data, has_vector_db

def auto_setup_data():
    """è‡ªåŠ¨è®¾ç½®æ•°æ®"""
    logging.info("æ£€æŸ¥æ•°æ®çŠ¶æ€...")
    
    has_knowledge_data, has_vector_db = check_data_exists()
    
    if not has_knowledge_data:
        logging.info("æœªå‘ç°çŸ¥è¯†åº“æ•°æ®ï¼Œå¼€å§‹è‡ªåŠ¨çˆ¬å–...")
        crawl_data_auto()
    else:
        logging.info("å‘ç°çŸ¥è¯†åº“æ•°æ®ï¼Œè·³è¿‡çˆ¬å–æ­¥éª¤")
    
    if not has_vector_db:
        if has_knowledge_data:
            logging.info("å‘ç°çŸ¥è¯†åº“æ•°æ®ä½†å‘é‡æ•°æ®åº“ä¸å­˜åœ¨ï¼Œå¼€å§‹ä»ç°æœ‰æ•°æ®æ„å»ºå‘é‡æ•°æ®åº“...")
        else:
            logging.info("æœªå‘ç°å‘é‡æ•°æ®åº“ï¼Œå¼€å§‹æ„å»º...")
        build_database_auto()
    else:
        logging.info("å‘ç°å‘é‡æ•°æ®åº“ï¼Œè·³è¿‡æ„å»ºæ­¥éª¤")

def crawl_data_auto():
    """è‡ªåŠ¨æ•°æ®é‡‡é›†"""
    from data_collection.crawler import DataCollector
    
    logging.info("å¼€å§‹è‡ªåŠ¨æ•°æ®é‡‡é›†...")
    
    collector = DataCollector()
    results = collector.crawl_all_sites()
    
    if results:
        filepath = collector.save_results(results)
        logging.info(f"æ•°æ®é‡‡é›†å®Œæˆï¼Œä¿å­˜åˆ°: {filepath}")
        
        # è‡ªåŠ¨ç¿»è¯‘
        from data_collection.translator import ContentTranslator
        translator = ContentTranslator(model_provider="zhipu")
        translated_results = translator.translate_crawl_results(results)
        translator.save_translated_results(translated_results)
        logging.info("ç¿»è¯‘å®Œæˆ")
    else:
        logging.warning("æœªè·å–åˆ°ä»»ä½•æ•°æ®")

def build_database_auto():
    """è‡ªåŠ¨æ„å»ºæ•°æ®åº“"""
    from database.create_db import DatabaseManager
    
    logging.info("å¼€å§‹æ„å»ºå‘é‡æ•°æ®åº“...")
    
    manager = DatabaseManager()
    vectordb = manager.create_vector_db("m3e")
    
    if vectordb:
        logging.info("å‘é‡æ•°æ®åº“åˆ›å»ºæˆåŠŸ")
    else:
        logging.error("å‘é‡æ•°æ®åº“åˆ›å»ºå¤±è´¥")

def crawl_data(args):
    """æ•°æ®é‡‡é›†åŠŸèƒ½"""
    from data_collection.crawler import DataCollector
    
    logging.info("å¼€å§‹æ•°æ®é‡‡é›†...")
    
    collector = DataCollector()
    
    if args.all_sites:
        results = collector.crawl_all_sites()
    elif args.site:
        results = collector.crawl_site(args.site)
    else:
        logging.error("è¯·æŒ‡å®š --all-sites æˆ– --site å‚æ•°")
        return
    
    if results:
        filepath = collector.save_results(results)
        logging.info(f"æ•°æ®é‡‡é›†å®Œæˆï¼Œä¿å­˜åˆ°: {filepath}")
        
        # å¦‚æœæŒ‡å®šäº†ç¿»è¯‘ï¼Œåˆ™è¿›è¡Œç¿»è¯‘
        if args.translate:
            from data_collection.translator import ContentTranslator
            translator = ContentTranslator(model_provider=args.translate_model)
            translated_results = translator.translate_crawl_results(results)
            translator.save_translated_results(translated_results)
            logging.info("ç¿»è¯‘å®Œæˆ")
    else:
        logging.warning("æœªè·å–åˆ°ä»»ä½•æ•°æ®")

def build_database(args):
    """æ„å»ºæ•°æ®åº“åŠŸèƒ½"""
    from database.create_db import DatabaseManager
    
    logging.info("å¼€å§‹æ„å»ºå‘é‡æ•°æ®åº“...")
    
    manager = DatabaseManager()
    
    if args.action == "create":
        vectordb = manager.create_vector_db(args.embedding)
        if vectordb:
            logging.info("å‘é‡æ•°æ®åº“åˆ›å»ºæˆåŠŸ")
        else:
            logging.error("å‘é‡æ•°æ®åº“åˆ›å»ºå¤±è´¥")
    
    elif args.action == "update":
        manager.update_vector_db(args.embedding)
        logging.info("å‘é‡æ•°æ®åº“æ›´æ–°å®Œæˆ")
    
    elif args.action == "info":
        info = manager.get_db_info()
        logging.info(f"æ•°æ®åº“ä¿¡æ¯: {info}")

def test_qa(args):
    """æµ‹è¯•é—®ç­”åŠŸèƒ½"""
    from qa_chain.lcel_chain import QaChainManager
    
    logging.info("å¼€å§‹æµ‹è¯•é—®ç­”åŠŸèƒ½...")
    
    manager = QaChainManager()
    chain = manager.get_chain(
        model_provider=args.model,
        embedding_type=args.embedding
    )
    
    # æµ‹è¯•é—®é¢˜
    test_questions = [
        "ä»€ä¹ˆæ˜¯(G)I-DLE?",
        "ä»‹ç»ä¸€ä¸‹(G)I-DLEçš„æˆå‘˜",
        "å¥¹ä»¬çš„ä»£è¡¨ä½œæœ‰å“ªäº›?"
    ]
    
    for question in test_questions:
        logging.info(f"æµ‹è¯•é—®é¢˜: {question}")
        result = chain.answer(question)
        logging.info(f"å›ç­”: {result['answer']}")
        logging.info(f"æ¥æº: {result['sources']}")
        print("-" * 50)

def deploy_app(args):
    """éƒ¨ç½²åº”ç”¨åŠŸèƒ½"""
    if args.deploy == "local":
        # æœ¬åœ°éƒ¨ç½² - è‡ªåŠ¨æ£€æŸ¥æ•°æ®
        auto_setup_data()
        
        # å¯åŠ¨ Gradio åº”ç”¨
        from serve.gradio_app import GradioApp
        app = GradioApp()
        app.launch(share=args.share, port=args.port)
    
    elif args.deploy == "gradio":
        from serve.gradio_app import GradioApp
        app = GradioApp()
        app.launch(share=args.share, port=args.port)
    
    elif args.deploy == "streamlit":
        import subprocess
        cmd = f"streamlit run serve/streamlit_app.py --server.port {args.port}"
        subprocess.run(cmd, shell=True)

def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(
        description='(G)I-DLE Universe æ™ºèƒ½é—®ç­”ç³»ç»Ÿ',
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ä½¿ç”¨ç¤ºä¾‹:
  # çˆ¬å–æ‰€æœ‰ç½‘ç«™æ•°æ®
  python main.py --crawl --all-sites --translate
  
  # æ„å»ºå‘é‡æ•°æ®åº“
  python main.py --build-db --action create
  
  # æµ‹è¯•é—®ç­”åŠŸèƒ½
  python main.py --test-qa --model zhipu
  
  # å¯åŠ¨æœ¬åœ°éƒ¨ç½²ï¼ˆè‡ªåŠ¨æ£€æŸ¥æ•°æ®ï¼‰
  python main.py --deploy local --port 7860
  
  # å¯åŠ¨ Gradio åº”ç”¨
  python main.py --deploy gradio --port 7860
  
  # å¯åŠ¨ Streamlit åº”ç”¨
  python main.py --deploy streamlit --port 8501
        """
    )
    
    # æ•°æ®é‡‡é›†å‚æ•°
    parser.add_argument('--crawl', action='store_true', help='æ‰§è¡Œæ•°æ®é‡‡é›†')
    parser.add_argument('--all-sites', action='store_true', help='çˆ¬å–æ‰€æœ‰ç½‘ç«™')
    parser.add_argument('--site', type=str, help='æŒ‡å®šçˆ¬å–çš„ç½‘ç«™')
    parser.add_argument('--translate', action='store_true', help='ç¿»è¯‘é‡‡é›†çš„æ•°æ®')
    parser.add_argument('--translate-model', type=str, default='zhipu', 
                       choices=['zhipu', 'openai'], help='ç¿»è¯‘ä½¿ç”¨çš„æ¨¡å‹')
    
    # æ•°æ®åº“æ„å»ºå‚æ•°
    parser.add_argument('--build-db', action='store_true', help='æ„å»ºå‘é‡æ•°æ®åº“')
    parser.add_argument('--action', type=str, choices=['create', 'update', 'info'], 
                       default='create', help='æ•°æ®åº“æ“ä½œç±»å‹')
    parser.add_argument('--embedding', type=str, default='m3e', 
                       choices=['m3e', 'openai'], help='å‘é‡åŒ–æ¨¡å‹')
    
    # æµ‹è¯•å‚æ•°
    parser.add_argument('--test-qa', action='store_true', help='æµ‹è¯•é—®ç­”åŠŸèƒ½')
    parser.add_argument('--model', type=str, default='zhipu', 
                       choices=['zhipu', 'openai'], help='æµ‹è¯•ä½¿ç”¨çš„æ¨¡å‹')
    
    # éƒ¨ç½²å‚æ•°
    parser.add_argument('--deploy', type=str, choices=['local', 'gradio', 'streamlit'], 
                       help='éƒ¨ç½²ç±»å‹')
    parser.add_argument('--port', type=int, default=12820, help='ç«¯å£å·')
    parser.add_argument('--share', action='store_true', help='æ˜¯å¦åˆ†äº«é“¾æ¥')
    
    # å…¶ä»–å‚æ•°
    parser.add_argument('--verbose', action='store_true', help='è¯¦ç»†è¾“å‡º')
    
    args = parser.parse_args()
    
    # è®¾ç½®æ—¥å¿—çº§åˆ«
    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)
    else:
        setup_logging()
    
    # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
    print("ğŸµ (G)I-DLE Universe æ™ºèƒ½é—®ç­”ç³»ç»Ÿ")
    print("=" * 50)
    
    try:
        # æ‰§è¡Œç›¸åº”åŠŸèƒ½
        if args.crawl:
            crawl_data(args)
        
        elif args.build_db:
            build_database(args)
        
        elif args.test_qa:
            test_qa(args)
        
        elif args.deploy:
            deploy_app(args)
        
        else:
            parser.print_help()
    
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç¨‹åºå·²é€€å‡º")
    except Exception as e:
        logging.error(f"ç¨‹åºæ‰§è¡Œå‡ºé”™: {e}")
        if args.verbose:
            import traceback
            traceback.print_exc()

if __name__ == "__main__":
    main() 