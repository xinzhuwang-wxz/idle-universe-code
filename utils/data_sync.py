"""
æ•°æ®åŒæ­¥å·¥å…·
ç”¨äºå°†æœ¬åœ°æ•°æ®æ‰“åŒ…å¹¶å‡†å¤‡ä¸Šä¼ åˆ°çº¿ä¸Šéƒ¨ç½²å¹³å°
"""
import os
import json
import shutil
import zipfile
from datetime import datetime
from typing import Dict, List

class DataSync:
    """æ•°æ®åŒæ­¥å·¥å…·ç±»"""
    
    def __init__(self):
        self.project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
        self.data_dir = os.path.join(self.project_root, "data_package")
        
        # ç¡®ä¿æ•°æ®ç›®å½•å­˜åœ¨
        os.makedirs(self.data_dir, exist_ok=True)
    
    def create_data_package(self, include_vector_db: bool = True) -> str:
        """åˆ›å»ºæ•°æ®åŒ…"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        package_name = f"idle_universe_data_{timestamp}"
        package_path = os.path.join(self.data_dir, package_name)
        
        # åˆ›å»ºåŒ…ç›®å½•
        os.makedirs(package_path, exist_ok=True)
        
        # å¤åˆ¶çŸ¥è¯†åº“æ•°æ®
        self._copy_knowledge_db(package_path)
        
        # å¤åˆ¶å‘é‡æ•°æ®åº“ï¼ˆå¯é€‰ï¼‰
        if include_vector_db:
            self._copy_vector_db(package_path)
        
        # åˆ›å»ºæ•°æ®åŒ…ä¿¡æ¯
        self._create_package_info(package_path, include_vector_db)
        
        # åˆ›å»ºå‹ç¼©åŒ…
        zip_path = self._create_zip_package(package_path, package_name)
        
        print(f"âœ… æ•°æ®åŒ…åˆ›å»ºå®Œæˆ: {zip_path}")
        return zip_path
    
    def _copy_knowledge_db(self, package_path: str):
        """å¤åˆ¶çŸ¥è¯†åº“æ•°æ®"""
        source_dir = os.path.join(self.project_root, "knowledge_db")
        target_dir = os.path.join(package_path, "knowledge_db")
        
        if os.path.exists(source_dir):
            shutil.copytree(source_dir, target_dir, dirs_exist_ok=True)
            print(f"ğŸ“ å·²å¤åˆ¶çŸ¥è¯†åº“æ•°æ®åˆ°: {target_dir}")
        else:
            print("âš ï¸  çŸ¥è¯†åº“ç›®å½•ä¸å­˜åœ¨")
    
    def _copy_vector_db(self, package_path: str):
        """å¤åˆ¶å‘é‡æ•°æ®åº“"""
        source_dir = os.path.join(self.project_root, "vector_db")
        target_dir = os.path.join(package_path, "vector_db")
        
        if os.path.exists(source_dir):
            shutil.copytree(source_dir, target_dir, dirs_exist_ok=True)
            print(f"ğŸ“ å·²å¤åˆ¶å‘é‡æ•°æ®åº“åˆ°: {target_dir}")
        else:
            print("âš ï¸  å‘é‡æ•°æ®åº“ç›®å½•ä¸å­˜åœ¨")
    
    def _create_package_info(self, package_path: str, include_vector_db: bool):
        """åˆ›å»ºæ•°æ®åŒ…ä¿¡æ¯æ–‡ä»¶"""
        info = {
            "package_created": datetime.now().isoformat(),
            "includes_vector_db": include_vector_db,
            "data_sources": {
                "knowledge_db": "processed/translated_results_20250804_001500.json",
                "vector_db": "chroma/" if include_vector_db else None
            },
            "deployment_instructions": [
                "1. è§£å‹æ•°æ®åŒ…åˆ°é¡¹ç›®æ ¹ç›®å½•",
                "2. ç¡®ä¿ knowledge_db å’Œ vector_db ç›®å½•åœ¨æ­£ç¡®ä½ç½®",
                "3. å¯åŠ¨åº”ç”¨å³å¯ä½¿ç”¨"
            ]
        }
        
        info_path = os.path.join(package_path, "package_info.json")
        with open(info_path, 'w', encoding='utf-8') as f:
            json.dump(info, f, ensure_ascii=False, indent=2)
        
        print(f"ğŸ“„ å·²åˆ›å»ºæ•°æ®åŒ…ä¿¡æ¯: {info_path}")
    
    def _create_zip_package(self, package_path: str, package_name: str) -> str:
        """åˆ›å»ºå‹ç¼©åŒ…"""
        zip_path = f"{package_path}.zip"
        
        with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zipf:
            for root, dirs, files in os.walk(package_path):
                for file in files:
                    file_path = os.path.join(root, file)
                    arcname = os.path.relpath(file_path, package_path)
                    zipf.write(file_path, arcname)
        
        # æ¸…ç†ä¸´æ—¶ç›®å½•
        shutil.rmtree(package_path)
        
        return zip_path
    
    def get_deployment_guide(self) -> str:
        """è·å–éƒ¨ç½²æŒ‡å—"""
        guide = """
# (G)I-DLE Universe çº¿ä¸Šéƒ¨ç½²æŒ‡å—

## 1. å¹³å°é€‰æ‹©

### Streamlit Cloud (æ¨è)
- å…è´¹é¢åº¦ï¼šæ¯æœˆ 750 å°æ—¶
- è‡ªåŠ¨éƒ¨ç½²ï¼šè¿æ¥ GitHub ä»“åº“
- æ”¯æŒï¼šPython 3.9+

### Railway
- å…è´¹é¢åº¦ï¼šæ¯æœˆ $5
- ç®€å•éƒ¨ç½²ï¼šä¸Šä¼ ä»£ç å³å¯
- æ”¯æŒï¼šå¤šç§ç¼–ç¨‹è¯­è¨€

### Render
- å…è´¹é¢åº¦ï¼šæ¯æœˆ 750 å°æ—¶
- è‡ªåŠ¨éƒ¨ç½²ï¼šè¿æ¥ Git ä»“åº“
- æ”¯æŒï¼šPython, Node.js ç­‰

## 2. æ•°æ®åŒæ­¥æ­¥éª¤

### æ­¥éª¤ 1: åˆ›å»ºæ•°æ®åŒ…
```bash
python utils/data_sync.py --create-package
```

### æ­¥éª¤ 2: ä¸Šä¼ æ•°æ®åŒ…
- å°†ç”Ÿæˆçš„ zip æ–‡ä»¶ä¸Šä¼ åˆ°éƒ¨ç½²å¹³å°
- æˆ–ä½¿ç”¨ Git LFS ç®¡ç†å¤§æ–‡ä»¶

### æ­¥éª¤ 3: é…ç½®ç¯å¢ƒå˜é‡
```env
ZHIPUAI_API_KEY=your_zhipuai_api_key
OPENAI_API_KEY=your_openai_api_key (å¯é€‰)
```

## 3. éƒ¨ç½²é…ç½®

### requirements.txt å·²åŒ…å«æ‰€æœ‰ä¾èµ–
### å…¥å£æ–‡ä»¶: serve/streamlit_app.py

## 4. æ³¨æ„äº‹é¡¹
- å‘é‡æ•°æ®åº“æ–‡ä»¶è¾ƒå¤§ï¼Œå»ºè®®ä½¿ç”¨ Git LFS
- ç¡®ä¿ API å¯†é’¥å®‰å…¨å­˜å‚¨
- å®šæœŸæ›´æ–°çŸ¥è¯†åº“æ•°æ®
        """
        return guide

def main():
    """ä¸»å‡½æ•°"""
    import argparse
    
    parser = argparse.ArgumentParser(description='æ•°æ®åŒæ­¥å·¥å…·')
    parser.add_argument('--create-package', action='store_true', help='åˆ›å»ºæ•°æ®åŒ…')
    parser.add_argument('--include-vector-db', action='store_true', default=True, help='åŒ…å«å‘é‡æ•°æ®åº“')
    parser.add_argument('--show-guide', action='store_true', help='æ˜¾ç¤ºéƒ¨ç½²æŒ‡å—')
    
    args = parser.parse_args()
    
    sync = DataSync()
    
    if args.create_package:
        package_path = sync.create_data_package(args.include_vector_db)
        print(f"\nğŸ‰ æ•°æ®åŒ…å·²åˆ›å»º: {package_path}")
        print("ğŸ“¦ ç°åœ¨å¯ä»¥å°†æ­¤æ–‡ä»¶ä¸Šä¼ åˆ°éƒ¨ç½²å¹³å°")
    
    if args.show_guide:
        print(sync.get_deployment_guide())

if __name__ == "__main__":
    main() 